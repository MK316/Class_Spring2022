{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyObVO77J1QJTQvpiRGOVmBy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/Class_Spring2022/blob/main/stress160.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 7 Stress and intonation (F23)"
      ],
      "metadata": {
        "id": "zhqKIwu7w8Kn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Wordlist 160](https://raw.githubusercontent.com/MK316/Myapps/main/data/stress160.csv)"
      ],
      "metadata": {
        "id": "y6vJiTHDu5RH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-mB6lyMyFr5"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install gradio pandas gtts requests librosa matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Gradio link\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import requests\n",
        "from gtts import gTTS\n",
        "from io import BytesIO\n",
        "\n",
        "# URL of the raw CSV file on GitHub\n",
        "csv_url = 'https://raw.githubusercontent.com/MK316/Myapps/main/data/stress160.csv'\n",
        "\n",
        "# Use requests to get the CSV file content from GitHub\n",
        "response = requests.get(csv_url)\n",
        "assert response.status_code == 200, 'Failed to download CSV file'\n",
        "\n",
        "# Load the CSV content into a DataFrame\n",
        "df = pd.read_csv(BytesIO(response.content))\n",
        "\n",
        "def generate_audio_by_id(word_id):\n",
        "    word = df.loc[df['ID'] == word_id, 'Words'].values[0]\n",
        "    return text_to_speech(word)\n",
        "\n",
        "def generate_audio_by_word(word):\n",
        "    if word in df['Words'].values:\n",
        "        audio_path = text_to_speech(word)\n",
        "        return audio_path, \"\"  # Return the path and an empty status message\n",
        "    else:\n",
        "        return None, \"Word not found in the list.\"  # Return None and a status message\n",
        "\n",
        "\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "def text_to_speech(text):\n",
        "    tts = gTTS(text=text, lang='en')\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as f:\n",
        "        tts.save(f.name)\n",
        "        return f.name  # Return the path to the saved file\n",
        "\n",
        "\n",
        "def search_and_generate_audio(search_by, query):\n",
        "    if search_by == 'ID':\n",
        "        try:\n",
        "            query = int(query)  # Convert ID to integer\n",
        "            audio_path = generate_audio_by_id(query)\n",
        "            return audio_path, \"\"\n",
        "        except ValueError:\n",
        "            return None, \"ID must be an integer.\"\n",
        "    elif search_by == 'Words':\n",
        "        audio_path, status = generate_audio_by_word(query)\n",
        "        return audio_path, status\n",
        "    else:\n",
        "        return None, \"Please select a valid search option.\"\n",
        "\n",
        "\n",
        "# Define the Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=search_and_generate_audio,\n",
        "    inputs=[\n",
        "        gr.Radio(['ID', 'Words'], label=\"Search by:\"),\n",
        "        gr.Textbox(label=\"Enter ID or Word:\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Audio(label=\"Audio of the word\"),\n",
        "        gr.Textbox(label=\"Status\")\n",
        "    ],\n",
        "    title=\"Word Audio Generator\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch(debug=True)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "E00LZprLu-SZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read a sentence"
      ],
      "metadata": {
        "id": "VfUQ8V-hxQ-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Sentence reading\n",
        "import gradio as gr\n",
        "from gtts import gTTS\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "# Define the function to convert text to speech and save it to a temporary file\n",
        "def text_to_speech(text):\n",
        "    tts = gTTS(text=text, lang='en')\n",
        "    # Create a temporary file to save the audio\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as f:\n",
        "        tts.save(f.name)\n",
        "        # Return the path to the saved audio file\n",
        "        return f.name\n",
        "\n",
        "# Create the Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=text_to_speech,\n",
        "    inputs=gr.Textbox(placeholder=\"Type a sentence here...\"),\n",
        "    outputs=gr.Audio(),\n",
        "    title=\"Text to Speech\",\n",
        "    description=\"Enter a sentence to convert it to speech.\"\n",
        ")\n",
        "\n",
        "# Launch the interface and create a shareable link\n",
        "iface.launch(share=True)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "222-Be9oxTE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [2] Visible pitch contour (intonation)\n"
      ],
      "metadata": {
        "id": "vFtpgBBs_c63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Generate speech (word or sentence)\n",
        "from gtts import gTTS\n",
        "from pydub import AudioSegment\n",
        "from io import BytesIO\n",
        "\n",
        "# Function to generate and save a WAV file\n",
        "def generate_and_save_wav(word, filename='output.wav'):\n",
        "    # Generate speech using gTTS\n",
        "    tts = gTTS(text=word, lang='en')\n",
        "\n",
        "    # Save as MP3 in memory\n",
        "    mp3_fp = BytesIO()\n",
        "    tts.write_to_fp(mp3_fp)\n",
        "    mp3_fp.seek(0)\n",
        "\n",
        "    # Convert MP3 to WAV\n",
        "    sound = AudioSegment.from_file(mp3_fp, format=\"mp3\")\n",
        "    sound.export(filename, format=\"wav\")\n",
        "\n",
        "# Example usage\n",
        "mytext = input('Type a word or sentence: ')\n",
        "generate_and_save_wav(mytext)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zbOlUV0cMrBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Intonation contour (pitch)\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Function to extract and plot the pitch contour\n",
        "def plot_pitch_contour(audio_file_path):\n",
        "    # Load the audio file\n",
        "    y, sr = librosa.load(audio_file_path, sr=None)\n",
        "\n",
        "    # Define the range for expected pitch (fundamental frequency)\n",
        "    fmin = librosa.note_to_hz('C2')  # Example minimum pitch\n",
        "    fmax = librosa.note_to_hz('C6')  # Example maximum pitch\n",
        "\n",
        "    # Extract the pitch contour using YIN algorithm\n",
        "    pitch, voiced_flag, voiced_probs = librosa.pyin(y, fmin=fmin, fmax=fmax, sr=sr)\n",
        "\n",
        "    # Replace NaNs with zeros (unvoiced segments)\n",
        "    pitch[~np.isfinite(pitch)] = 0\n",
        "\n",
        "    # Plot the pitch contour\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    librosa.display.waveshow(y, sr=sr)\n",
        "    times = librosa.times_like(pitch, sr=sr)\n",
        "\n",
        "    # Plot only non-zero pitch values\n",
        "    for i in range(len(pitch)):\n",
        "        if pitch[i] > 0:\n",
        "            plt.plot(times[i], pitch[i], 'ro')  # Red dot for each non-zero pitch\n",
        "\n",
        "    plt.title('Pitch Contour')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Pitch (Hz)')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_pitch_contour('/content/output.wav')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_K2jjA2kPMHN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}